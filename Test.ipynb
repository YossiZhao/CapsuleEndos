{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05e6a6fc",
   "metadata": {},
   "source": [
    "### Load Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a4719533",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3560 27282 6349\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "\n",
    "class customDataset(Dataset):\n",
    "    def __init__(self, csv_file, data_dir, transform=None):\n",
    "        self.annotations = pd.read_csv(csv_file)\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        img_path = os.path.join(self.data_dir, self.annotations.iloc[index,1])\n",
    "        image = Image.open(img_path)\n",
    "        y_label = torch.tensor(int(self.annotations.iloc[index,2]))\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return (image, y_label)\n",
    "    \n",
    "\n",
    "transform = transforms.Compose([\n",
    "                                       transforms.Resize((224, 224)),\n",
    "                                       transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "# test_set = customDataset(csv_file='./data/test_CapsuleEndos.csv', data_dir='./data/test_CapsuleEndos', \\\n",
    "#                       transform=transform)    # 10197, 2 patients\n",
    "train_set = customDataset(csv_file='./data/train_CapsuleEndos.csv', data_dir='./data/train_CapsuleEndos', \\\n",
    "                      transform=transform) \n",
    "stomach = 0\n",
    "small = 0\n",
    "large = 0\n",
    "\n",
    "for data, label in train_set:\n",
    "    if label==0:\n",
    "        stomach += 1\n",
    "    elif label==1:\n",
    "        small += 1\n",
    "    elif label==2:\n",
    "        large += 1\n",
    "\n",
    "print(stomach, small, large)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710c9997",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f2e462cc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "EfficientNet(\n",
       "  (_conv_stem): Conv2dStaticSamePadding(\n",
       "    3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False\n",
       "    (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "  )\n",
       "  (_bn0): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (_blocks): ModuleList(\n",
       "    (0): MBConvBlock(\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        32, 32, kernel_size=(3, 3), stride=[1, 1], groups=32, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        32, 8, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        8, 32, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(16, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (1): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        96, 96, kernel_size=(3, 3), stride=[2, 2], groups=96, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        96, 4, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        4, 96, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (2): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        144, 144, kernel_size=(3, 3), stride=(1, 1), groups=144, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (3): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        144, 144, kernel_size=(5, 5), stride=[2, 2], groups=144, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 2, 1, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (4): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        240, 240, kernel_size=(5, 5), stride=(1, 1), groups=240, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (5): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        240, 240, kernel_size=(3, 3), stride=[2, 2], groups=240, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (6): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (7): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (8): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        480, 480, kernel_size=(5, 5), stride=[1, 1], groups=480, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (9): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (10): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (11): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        672, 672, kernel_size=(5, 5), stride=[2, 2], groups=672, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 2, 1, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (12): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (13): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (14): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (15): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1152, 1152, kernel_size=(3, 3), stride=[1, 1], groups=1152, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(320, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "  )\n",
       "  (_conv_head): Conv2dStaticSamePadding(\n",
       "    320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "    (static_padding): Identity()\n",
       "  )\n",
       "  (_bn1): BatchNorm2d(1280, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (_avg_pooling): AdaptiveAvgPool2d(output_size=1)\n",
       "  (_dropout): Dropout(p=0.2, inplace=False)\n",
       "  (_fc): Linear(in_features=1280, out_features=3, bias=True)\n",
       "  (_swish): MemoryEfficientSwish()\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from efficientnet_pytorch import EfficientNet\n",
    "model = EfficientNet.from_pretrained('efficientnet-b0', num_classes=3)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4f21e0",
   "metadata": {},
   "source": [
    "### Load Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5e93013e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for EfficientNet:\n\tMissing key(s) in state_dict: \"_conv_stem.weight\", \"_bn0.weight\", \"_bn0.bias\", \"_bn0.running_mean\", \"_bn0.running_var\", \"_blocks.0._depthwise_conv.weight\", \"_blocks.0._bn1.weight\", \"_blocks.0._bn1.bias\", \"_blocks.0._bn1.running_mean\", \"_blocks.0._bn1.running_var\", \"_blocks.0._se_reduce.weight\", \"_blocks.0._se_reduce.bias\", \"_blocks.0._se_expand.weight\", \"_blocks.0._se_expand.bias\", \"_blocks.0._project_conv.weight\", \"_blocks.0._bn2.weight\", \"_blocks.0._bn2.bias\", \"_blocks.0._bn2.running_mean\", \"_blocks.0._bn2.running_var\", \"_blocks.1._expand_conv.weight\", \"_blocks.1._bn0.weight\", \"_blocks.1._bn0.bias\", \"_blocks.1._bn0.running_mean\", \"_blocks.1._bn0.running_var\", \"_blocks.1._depthwise_conv.weight\", \"_blocks.1._bn1.weight\", \"_blocks.1._bn1.bias\", \"_blocks.1._bn1.running_mean\", \"_blocks.1._bn1.running_var\", \"_blocks.1._se_reduce.weight\", \"_blocks.1._se_reduce.bias\", \"_blocks.1._se_expand.weight\", \"_blocks.1._se_expand.bias\", \"_blocks.1._project_conv.weight\", \"_blocks.1._bn2.weight\", \"_blocks.1._bn2.bias\", \"_blocks.1._bn2.running_mean\", \"_blocks.1._bn2.running_var\", \"_blocks.2._expand_conv.weight\", \"_blocks.2._bn0.weight\", \"_blocks.2._bn0.bias\", \"_blocks.2._bn0.running_mean\", \"_blocks.2._bn0.running_var\", \"_blocks.2._depthwise_conv.weight\", \"_blocks.2._bn1.weight\", \"_blocks.2._bn1.bias\", \"_blocks.2._bn1.running_mean\", \"_blocks.2._bn1.running_var\", \"_blocks.2._se_reduce.weight\", \"_blocks.2._se_reduce.bias\", \"_blocks.2._se_expand.weight\", \"_blocks.2._se_expand.bias\", \"_blocks.2._project_conv.weight\", \"_blocks.2._bn2.weight\", \"_blocks.2._bn2.bias\", \"_blocks.2._bn2.running_mean\", \"_blocks.2._bn2.running_var\", \"_blocks.3._expand_conv.weight\", \"_blocks.3._bn0.weight\", \"_blocks.3._bn0.bias\", \"_blocks.3._bn0.running_mean\", \"_blocks.3._bn0.running_var\", \"_blocks.3._depthwise_conv.weight\", \"_blocks.3._bn1.weight\", \"_blocks.3._bn1.bias\", \"_blocks.3._bn1.running_mean\", \"_blocks.3._bn1.running_var\", \"_blocks.3._se_reduce.weight\", \"_blocks.3._se_reduce.bias\", \"_blocks.3._se_expand.weight\", \"_blocks.3._se_expand.bias\", \"_blocks.3._project_conv.weight\", \"_blocks.3._bn2.weight\", \"_blocks.3._bn2.bias\", \"_blocks.3._bn2.running_mean\", \"_blocks.3._bn2.running_var\", \"_blocks.4._expand_conv.weight\", \"_blocks.4._bn0.weight\", \"_blocks.4._bn0.bias\", \"_blocks.4._bn0.running_mean\", \"_blocks.4._bn0.running_var\", \"_blocks.4._depthwise_conv.weight\", \"_blocks.4._bn1.weight\", \"_blocks.4._bn1.bias\", \"_blocks.4._bn1.running_mean\", \"_blocks.4._bn1.running_var\", \"_blocks.4._se_reduce.weight\", \"_blocks.4._se_reduce.bias\", \"_blocks.4._se_expand.weight\", \"_blocks.4._se_expand.bias\", \"_blocks.4._project_conv.weight\", \"_blocks.4._bn2.weight\", \"_blocks.4._bn2.bias\", \"_blocks.4._bn2.running_mean\", \"_blocks.4._bn2.running_var\", \"_blocks.5._expand_conv.weight\", \"_blocks.5._bn0.weight\", \"_blocks.5._bn0.bias\", \"_blocks.5._bn0.running_mean\", \"_blocks.5._bn0.running_var\", \"_blocks.5._depthwise_conv.weight\", \"_blocks.5._bn1.weight\", \"_blocks.5._bn1.bias\", \"_blocks.5._bn1.running_mean\", \"_blocks.5._bn1.running_var\", \"_blocks.5._se_reduce.weight\", \"_blocks.5._se_reduce.bias\", \"_blocks.5._se_expand.weight\", \"_blocks.5._se_expand.bias\", \"_blocks.5._project_conv.weight\", \"_blocks.5._bn2.weight\", \"_blocks.5._bn2.bias\", \"_blocks.5._bn2.running_mean\", \"_blocks.5._bn2.running_var\", \"_blocks.6._expand_conv.weight\", \"_blocks.6._bn0.weight\", \"_blocks.6._bn0.bias\", \"_blocks.6._bn0.running_mean\", \"_blocks.6._bn0.running_var\", \"_blocks.6._depthwise_conv.weight\", \"_blocks.6._bn1.weight\", \"_blocks.6._bn1.bias\", \"_blocks.6._bn1.running_mean\", \"_blocks.6._bn1.running_var\", \"_blocks.6._se_reduce.weight\", \"_blocks.6._se_reduce.bias\", \"_blocks.6._se_expand.weight\", \"_blocks.6._se_expand.bias\", \"_blocks.6._project_conv.weight\", \"_blocks.6._bn2.weight\", \"_blocks.6._bn2.bias\", \"_blocks.6._bn2.running_mean\", \"_blocks.6._bn2.running_var\", \"_blocks.7._expand_conv.weight\", \"_blocks.7._bn0.weight\", \"_blocks.7._bn0.bias\", \"_blocks.7._bn0.running_mean\", \"_blocks.7._bn0.running_var\", \"_blocks.7._depthwise_conv.weight\", \"_blocks.7._bn1.weight\", \"_blocks.7._bn1.bias\", \"_blocks.7._bn1.running_mean\", \"_blocks.7._bn1.running_var\", \"_blocks.7._se_reduce.weight\", \"_blocks.7._se_reduce.bias\", \"_blocks.7._se_expand.weight\", \"_blocks.7._se_expand.bias\", \"_blocks.7._project_conv.weight\", \"_blocks.7._bn2.weight\", \"_blocks.7._bn2.bias\", \"_blocks.7._bn2.running_mean\", \"_blocks.7._bn2.running_var\", \"_blocks.8._expand_conv.weight\", \"_blocks.8._bn0.weight\", \"_blocks.8._bn0.bias\", \"_blocks.8._bn0.running_mean\", \"_blocks.8._bn0.running_var\", \"_blocks.8._depthwise_conv.weight\", \"_blocks.8._bn1.weight\", \"_blocks.8._bn1.bias\", \"_blocks.8._bn1.running_mean\", \"_blocks.8._bn1.running_var\", \"_blocks.8._se_reduce.weight\", \"_blocks.8._se_reduce.bias\", \"_blocks.8._se_expand.weight\", \"_blocks.8._se_expand.bias\", \"_blocks.8._project_conv.weight\", \"_blocks.8._bn2.weight\", \"_blocks.8._bn2.bias\", \"_blocks.8._bn2.running_mean\", \"_blocks.8._bn2.running_var\", \"_blocks.9._expand_conv.weight\", \"_blocks.9._bn0.weight\", \"_blocks.9._bn0.bias\", \"_blocks.9._bn0.running_mean\", \"_blocks.9._bn0.running_var\", \"_blocks.9._depthwise_conv.weight\", \"_blocks.9._bn1.weight\", \"_blocks.9._bn1.bias\", \"_blocks.9._bn1.running_mean\", \"_blocks.9._bn1.running_var\", \"_blocks.9._se_reduce.weight\", \"_blocks.9._se_reduce.bias\", \"_blocks.9._se_expand.weight\", \"_blocks.9._se_expand.bias\", \"_blocks.9._project_conv.weight\", \"_blocks.9._bn2.weight\", \"_blocks.9._bn2.bias\", \"_blocks.9._bn2.running_mean\", \"_blocks.9._bn2.running_var\", \"_blocks.10._expand_conv.weight\", \"_blocks.10._bn0.weight\", \"_blocks.10._bn0.bias\", \"_blocks.10._bn0.running_mean\", \"_blocks.10._bn0.running_var\", \"_blocks.10._depthwise_conv.weight\", \"_blocks.10._bn1.weight\", \"_blocks.10._bn1.bias\", \"_blocks.10._bn1.running_mean\", \"_blocks.10._bn1.running_var\", \"_blocks.10._se_reduce.weight\", \"_blocks.10._se_reduce.bias\", \"_blocks.10._se_expand.weight\", \"_blocks.10._se_expand.bias\", \"_blocks.10._project_conv.weight\", \"_blocks.10._bn2.weight\", \"_blocks.10._bn2.bias\", \"_blocks.10._bn2.running_mean\", \"_blocks.10._bn2.running_var\", \"_blocks.11._expand_conv.weight\", \"_blocks.11._bn0.weight\", \"_blocks.11._bn0.bias\", \"_blocks.11._bn0.running_mean\", \"_blocks.11._bn0.running_var\", \"_blocks.11._depthwise_conv.weight\", \"_blocks.11._bn1.weight\", \"_blocks.11._bn1.bias\", \"_blocks.11._bn1.running_mean\", \"_blocks.11._bn1.running_var\", \"_blocks.11._se_reduce.weight\", \"_blocks.11._se_reduce.bias\", \"_blocks.11._se_expand.weight\", \"_blocks.11._se_expand.bias\", \"_blocks.11._project_conv.weight\", \"_blocks.11._bn2.weight\", \"_blocks.11._bn2.bias\", \"_blocks.11._bn2.running_mean\", \"_blocks.11._bn2.running_var\", \"_blocks.12._expand_conv.weight\", \"_blocks.12._bn0.weight\", \"_blocks.12._bn0.bias\", \"_blocks.12._bn0.running_mean\", \"_blocks.12._bn0.running_var\", \"_blocks.12._depthwise_conv.weight\", \"_blocks.12._bn1.weight\", \"_blocks.12._bn1.bias\", \"_blocks.12._bn1.running_mean\", \"_blocks.12._bn1.running_var\", \"_blocks.12._se_reduce.weight\", \"_blocks.12._se_reduce.bias\", \"_blocks.12._se_expand.weight\", \"_blocks.12._se_expand.bias\", \"_blocks.12._project_conv.weight\", \"_blocks.12._bn2.weight\", \"_blocks.12._bn2.bias\", \"_blocks.12._bn2.running_mean\", \"_blocks.12._bn2.running_var\", \"_blocks.13._expand_conv.weight\", \"_blocks.13._bn0.weight\", \"_blocks.13._bn0.bias\", \"_blocks.13._bn0.running_mean\", \"_blocks.13._bn0.running_var\", \"_blocks.13._depthwise_conv.weight\", \"_blocks.13._bn1.weight\", \"_blocks.13._bn1.bias\", \"_blocks.13._bn1.running_mean\", \"_blocks.13._bn1.running_var\", \"_blocks.13._se_reduce.weight\", \"_blocks.13._se_reduce.bias\", \"_blocks.13._se_expand.weight\", \"_blocks.13._se_expand.bias\", \"_blocks.13._project_conv.weight\", \"_blocks.13._bn2.weight\", \"_blocks.13._bn2.bias\", \"_blocks.13._bn2.running_mean\", \"_blocks.13._bn2.running_var\", \"_blocks.14._expand_conv.weight\", \"_blocks.14._bn0.weight\", \"_blocks.14._bn0.bias\", \"_blocks.14._bn0.running_mean\", \"_blocks.14._bn0.running_var\", \"_blocks.14._depthwise_conv.weight\", \"_blocks.14._bn1.weight\", \"_blocks.14._bn1.bias\", \"_blocks.14._bn1.running_mean\", \"_blocks.14._bn1.running_var\", \"_blocks.14._se_reduce.weight\", \"_blocks.14._se_reduce.bias\", \"_blocks.14._se_expand.weight\", \"_blocks.14._se_expand.bias\", \"_blocks.14._project_conv.weight\", \"_blocks.14._bn2.weight\", \"_blocks.14._bn2.bias\", \"_blocks.14._bn2.running_mean\", \"_blocks.14._bn2.running_var\", \"_blocks.15._expand_conv.weight\", \"_blocks.15._bn0.weight\", \"_blocks.15._bn0.bias\", \"_blocks.15._bn0.running_mean\", \"_blocks.15._bn0.running_var\", \"_blocks.15._depthwise_conv.weight\", \"_blocks.15._bn1.weight\", \"_blocks.15._bn1.bias\", \"_blocks.15._bn1.running_mean\", \"_blocks.15._bn1.running_var\", \"_blocks.15._se_reduce.weight\", \"_blocks.15._se_reduce.bias\", \"_blocks.15._se_expand.weight\", \"_blocks.15._se_expand.bias\", \"_blocks.15._project_conv.weight\", \"_blocks.15._bn2.weight\", \"_blocks.15._bn2.bias\", \"_blocks.15._bn2.running_mean\", \"_blocks.15._bn2.running_var\", \"_conv_head.weight\", \"_bn1.weight\", \"_bn1.bias\", \"_bn1.running_mean\", \"_bn1.running_var\", \"_fc.weight\", \"_fc.bias\". \n\tUnexpected key(s) in state_dict: \"conv1.weight\", \"bn1.weight\", \"bn1.bias\", \"bn1.running_mean\", \"bn1.running_var\", \"bn1.num_batches_tracked\", \"layer1.0.conv1.weight\", \"layer1.0.bn1.weight\", \"layer1.0.bn1.bias\", \"layer1.0.bn1.running_mean\", \"layer1.0.bn1.running_var\", \"layer1.0.bn1.num_batches_tracked\", \"layer1.0.conv2.weight\", \"layer1.0.bn2.weight\", \"layer1.0.bn2.bias\", \"layer1.0.bn2.running_mean\", \"layer1.0.bn2.running_var\", \"layer1.0.bn2.num_batches_tracked\", \"layer1.1.conv1.weight\", \"layer1.1.bn1.weight\", \"layer1.1.bn1.bias\", \"layer1.1.bn1.running_mean\", \"layer1.1.bn1.running_var\", \"layer1.1.bn1.num_batches_tracked\", \"layer1.1.conv2.weight\", \"layer1.1.bn2.weight\", \"layer1.1.bn2.bias\", \"layer1.1.bn2.running_mean\", \"layer1.1.bn2.running_var\", \"layer1.1.bn2.num_batches_tracked\", \"layer1.2.conv1.weight\", \"layer1.2.bn1.weight\", \"layer1.2.bn1.bias\", \"layer1.2.bn1.running_mean\", \"layer1.2.bn1.running_var\", \"layer1.2.bn1.num_batches_tracked\", \"layer1.2.conv2.weight\", \"layer1.2.bn2.weight\", \"layer1.2.bn2.bias\", \"layer1.2.bn2.running_mean\", \"layer1.2.bn2.running_var\", \"layer1.2.bn2.num_batches_tracked\", \"layer2.0.conv1.weight\", \"layer2.0.bn1.weight\", \"layer2.0.bn1.bias\", \"layer2.0.bn1.running_mean\", \"layer2.0.bn1.running_var\", \"layer2.0.bn1.num_batches_tracked\", \"layer2.0.conv2.weight\", \"layer2.0.bn2.weight\", \"layer2.0.bn2.bias\", \"layer2.0.bn2.running_mean\", \"layer2.0.bn2.running_var\", \"layer2.0.bn2.num_batches_tracked\", \"layer2.0.downsample.0.weight\", \"layer2.0.downsample.1.weight\", \"layer2.0.downsample.1.bias\", \"layer2.0.downsample.1.running_mean\", \"layer2.0.downsample.1.running_var\", \"layer2.0.downsample.1.num_batches_tracked\", \"layer2.1.conv1.weight\", \"layer2.1.bn1.weight\", \"layer2.1.bn1.bias\", \"layer2.1.bn1.running_mean\", \"layer2.1.bn1.running_var\", \"layer2.1.bn1.num_batches_tracked\", \"layer2.1.conv2.weight\", \"layer2.1.bn2.weight\", \"layer2.1.bn2.bias\", \"layer2.1.bn2.running_mean\", \"layer2.1.bn2.running_var\", \"layer2.1.bn2.num_batches_tracked\", \"layer2.2.conv1.weight\", \"layer2.2.bn1.weight\", \"layer2.2.bn1.bias\", \"layer2.2.bn1.running_mean\", \"layer2.2.bn1.running_var\", \"layer2.2.bn1.num_batches_tracked\", \"layer2.2.conv2.weight\", \"layer2.2.bn2.weight\", \"layer2.2.bn2.bias\", \"layer2.2.bn2.running_mean\", \"layer2.2.bn2.running_var\", \"layer2.2.bn2.num_batches_tracked\", \"layer2.3.conv1.weight\", \"layer2.3.bn1.weight\", \"layer2.3.bn1.bias\", \"layer2.3.bn1.running_mean\", \"layer2.3.bn1.running_var\", \"layer2.3.bn1.num_batches_tracked\", \"layer2.3.conv2.weight\", \"layer2.3.bn2.weight\", \"layer2.3.bn2.bias\", \"layer2.3.bn2.running_mean\", \"layer2.3.bn2.running_var\", \"layer2.3.bn2.num_batches_tracked\", \"layer3.0.conv1.weight\", \"layer3.0.bn1.weight\", \"layer3.0.bn1.bias\", \"layer3.0.bn1.running_mean\", \"layer3.0.bn1.running_var\", \"layer3.0.bn1.num_batches_tracked\", \"layer3.0.conv2.weight\", \"layer3.0.bn2.weight\", \"layer3.0.bn2.bias\", \"layer3.0.bn2.running_mean\", \"layer3.0.bn2.running_var\", \"layer3.0.bn2.num_batches_tracked\", \"layer3.0.downsample.0.weight\", \"layer3.0.downsample.1.weight\", \"layer3.0.downsample.1.bias\", \"layer3.0.downsample.1.running_mean\", \"layer3.0.downsample.1.running_var\", \"layer3.0.downsample.1.num_batches_tracked\", \"layer3.1.conv1.weight\", \"layer3.1.bn1.weight\", \"layer3.1.bn1.bias\", \"layer3.1.bn1.running_mean\", \"layer3.1.bn1.running_var\", \"layer3.1.bn1.num_batches_tracked\", \"layer3.1.conv2.weight\", \"layer3.1.bn2.weight\", \"layer3.1.bn2.bias\", \"layer3.1.bn2.running_mean\", \"layer3.1.bn2.running_var\", \"layer3.1.bn2.num_batches_tracked\", \"layer3.2.conv1.weight\", \"layer3.2.bn1.weight\", \"layer3.2.bn1.bias\", \"layer3.2.bn1.running_mean\", \"layer3.2.bn1.running_var\", \"layer3.2.bn1.num_batches_tracked\", \"layer3.2.conv2.weight\", \"layer3.2.bn2.weight\", \"layer3.2.bn2.bias\", \"layer3.2.bn2.running_mean\", \"layer3.2.bn2.running_var\", \"layer3.2.bn2.num_batches_tracked\", \"layer3.3.conv1.weight\", \"layer3.3.bn1.weight\", \"layer3.3.bn1.bias\", \"layer3.3.bn1.running_mean\", \"layer3.3.bn1.running_var\", \"layer3.3.bn1.num_batches_tracked\", \"layer3.3.conv2.weight\", \"layer3.3.bn2.weight\", \"layer3.3.bn2.bias\", \"layer3.3.bn2.running_mean\", \"layer3.3.bn2.running_var\", \"layer3.3.bn2.num_batches_tracked\", \"layer3.4.conv1.weight\", \"layer3.4.bn1.weight\", \"layer3.4.bn1.bias\", \"layer3.4.bn1.running_mean\", \"layer3.4.bn1.running_var\", \"layer3.4.bn1.num_batches_tracked\", \"layer3.4.conv2.weight\", \"layer3.4.bn2.weight\", \"layer3.4.bn2.bias\", \"layer3.4.bn2.running_mean\", \"layer3.4.bn2.running_var\", \"layer3.4.bn2.num_batches_tracked\", \"layer3.5.conv1.weight\", \"layer3.5.bn1.weight\", \"layer3.5.bn1.bias\", \"layer3.5.bn1.running_mean\", \"layer3.5.bn1.running_var\", \"layer3.5.bn1.num_batches_tracked\", \"layer3.5.conv2.weight\", \"layer3.5.bn2.weight\", \"layer3.5.bn2.bias\", \"layer3.5.bn2.running_mean\", \"layer3.5.bn2.running_var\", \"layer3.5.bn2.num_batches_tracked\", \"layer4.0.conv1.weight\", \"layer4.0.bn1.weight\", \"layer4.0.bn1.bias\", \"layer4.0.bn1.running_mean\", \"layer4.0.bn1.running_var\", \"layer4.0.bn1.num_batches_tracked\", \"layer4.0.conv2.weight\", \"layer4.0.bn2.weight\", \"layer4.0.bn2.bias\", \"layer4.0.bn2.running_mean\", \"layer4.0.bn2.running_var\", \"layer4.0.bn2.num_batches_tracked\", \"layer4.0.downsample.0.weight\", \"layer4.0.downsample.1.weight\", \"layer4.0.downsample.1.bias\", \"layer4.0.downsample.1.running_mean\", \"layer4.0.downsample.1.running_var\", \"layer4.0.downsample.1.num_batches_tracked\", \"layer4.1.conv1.weight\", \"layer4.1.bn1.weight\", \"layer4.1.bn1.bias\", \"layer4.1.bn1.running_mean\", \"layer4.1.bn1.running_var\", \"layer4.1.bn1.num_batches_tracked\", \"layer4.1.conv2.weight\", \"layer4.1.bn2.weight\", \"layer4.1.bn2.bias\", \"layer4.1.bn2.running_mean\", \"layer4.1.bn2.running_var\", \"layer4.1.bn2.num_batches_tracked\", \"layer4.2.conv1.weight\", \"layer4.2.bn1.weight\", \"layer4.2.bn1.bias\", \"layer4.2.bn1.running_mean\", \"layer4.2.bn1.running_var\", \"layer4.2.bn1.num_batches_tracked\", \"layer4.2.conv2.weight\", \"layer4.2.bn2.weight\", \"layer4.2.bn2.bias\", \"layer4.2.bn2.running_mean\", \"layer4.2.bn2.running_var\", \"layer4.2.bn2.num_batches_tracked\", \"fc.weight\", \"fc.bias\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_27724/1718779685.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model_effi-b0_weights.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/python37_pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1481\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1482\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m-> 1483\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m   1484\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for EfficientNet:\n\tMissing key(s) in state_dict: \"_conv_stem.weight\", \"_bn0.weight\", \"_bn0.bias\", \"_bn0.running_mean\", \"_bn0.running_var\", \"_blocks.0._depthwise_conv.weight\", \"_blocks.0._bn1.weight\", \"_blocks.0._bn1.bias\", \"_blocks.0._bn1.running_mean\", \"_blocks.0._bn1.running_var\", \"_blocks.0._se_reduce.weight\", \"_blocks.0._se_reduce.bias\", \"_blocks.0._se_expand.weight\", \"_blocks.0._se_expand.bias\", \"_blocks.0._project_conv.weight\", \"_blocks.0._bn2.weight\", \"_blocks.0._bn2.bias\", \"_blocks.0._bn2.running_mean\", \"_blocks.0._bn2.running_var\", \"_blocks.1._expand_conv.weight\", \"_blocks.1._bn0.weight\", \"_blocks.1._bn0.bias\", \"_blocks.1._bn0.running_mean\", \"_blocks.1._bn0.running_var\", \"_blocks.1._depthwise_conv.weight\", \"_blocks.1._bn1.weight\", \"_blocks.1._bn1.bias\", \"_blocks.1._bn1.running_mean\", \"_blocks.1._bn1.running_var\", \"_blocks.1._se_reduce.weight\", \"_blocks.1._se_reduce.bias\", \"_blocks.1._se_expand.weight\", \"_blocks.1._se_expand.bias\", \"_blocks.1._project_conv.weight\", \"_blocks.1._bn2.weight\", \"_blocks.1._bn2.bias\", \"_blocks.1._bn2.running_mean\", \"_blocks.1._bn2.running_var\", \"_blocks.2._expand_conv.weight\", \"_blocks.2._bn0.weight\", \"_blocks.2._bn0.bias\", \"_blocks.2._bn0.running_mean\", \"_blocks.2._bn0.running_var\", \"_blocks.2._depthwise_conv.weight\", \"_blocks.2._bn1.weight\", \"_blocks.2._bn1.bias\", \"_blocks.2._bn1.running_mean\", \"_blocks.2._bn1.running_var\", \"_blocks.2._se_reduce.weight\", \"_blocks.2._se_reduce.bias\", \"_blocks.2._se_expand.weight\", \"_blocks.2._se_expand.bias\", \"_blocks.2._project_conv.weight\", \"_blocks.2._bn2.weight\", \"_blocks.2._bn2.bias\", \"_blocks.2._bn2.running_mean\", \"_blocks.2._bn2.running_var\", \"_blocks.3._expand_conv.weight\", \"_blocks.3._bn0.weight\", \"_blocks.3._bn0.bias\", \"_blocks.3._bn0.running_mean\", \"_blocks.3._bn0.running_var\", \"_blocks.3._depthwise_conv.weight\", \"_blocks.3._bn1.weight\", \"_blocks.3._bn1.bias\", \"_blocks.3._bn1.running_mean\", \"_blocks.3._bn1.running_var\", \"_blocks.3._se_reduce.weight\", \"_blocks.3._se_reduce.bias\", \"_blocks.3._se_expand.weight\", \"_blocks.3._se_expand.bias\", \"_blocks.3._project_conv.weight\", \"_blocks.3._bn2.weight\", \"_blocks.3._bn2.bias\", \"_blocks.3._bn2.running_mean\", \"_blocks.3._bn2.running_var\", \"_blocks.4._expand_conv.weight\", \"_blocks.4._bn0.weight\", \"_blocks.4._bn0.bias\", \"_blocks.4._bn0.running_mean\", \"_blocks.4._bn0.running_var\", \"_blocks.4._depthwise_conv.weight\", \"_blocks.4._bn1.weight\", \"_blocks.4._bn1.bias\", \"_blocks.4._bn1.running_mean\", \"_blocks.4._bn1.running_var\", \"_blocks.4._se_reduce.weight\", \"_blocks.4._se_reduce.bias\", \"_blocks.4._se_expand.weight\", \"_blocks.4._se_expand.bias\", \"_blocks.4._project_conv.weight\", \"_blocks.4._bn2.weight\", \"_blocks.4._bn2.bias\", \"_blocks.4._bn2.running_mean\", \"_blocks.4._bn2.running_var\", \"_blocks.5._expand_conv.weight\", \"_blocks.5._bn0.weight\", \"_blocks.5._bn0.bias\", \"_blocks.5._bn0.running_mean\", \"_blocks.5._bn0.running_var\", \"_blocks.5._depthwise_conv.weight\", \"_blocks.5._bn1.weight\", \"_blocks.5._bn1.bias\", \"_blocks.5._bn1.running_mean\", \"_blocks.5._bn1.running_var\", \"_blocks.5._se_reduce.weight\", \"_blocks.5._se_reduce.bias\", \"_blocks.5._se_expand.weight\", \"_blocks.5._se_expand.bias\", \"_blocks.5._project_conv.weight\", \"_blocks.5._bn2.weight\", \"_blocks.5._bn2.bias\", \"_blocks.5._bn2.running_mean\", \"_blocks.5._bn2.running_var\", \"_blocks.6._expand_conv.weight\", \"_blocks.6._bn0.weight\", \"_blocks.6._bn0.bias\", \"_blocks.6._bn0.running_mean\", \"_blocks.6._bn0.running_var\", \"_blocks.6._depthwise_conv.weight\", \"_blocks.6._bn1.weight\", \"_blocks.6._bn1.bias\", \"_blocks.6._bn1.running_mean\", \"_blocks.6._bn1.running_var\", \"_blocks.6._se_reduce.weight\", \"_blocks.6._se_reduce.bias\", \"_blocks.6._se_expand.weight\", \"_blocks.6._se_expand.bias\", \"_blocks.6._project_conv.weight\", \"_blocks.6._bn2.weight\", \"_blocks.6._bn2.bias\", \"_blocks.6._bn2.running_mean\", \"_blocks.6._bn2.running_var\", \"_blocks.7._expand_conv.weight\", \"_blocks.7._bn0.weight\", \"_blocks.7._bn0.bias\", \"_blocks.7._bn0.running_mean\", \"_blocks.7._bn0.running_var\", \"_blocks.7._depthwise_conv.weight\", \"_blocks.7._bn1.weight\", \"_blocks.7._bn1.bias\", \"_blocks.7._bn1.running_mean\", \"_blocks.7._bn1.running_var\", \"_blocks.7._se_reduce.weight\", \"_blocks.7._se_reduce.bias\", \"_blocks.7._se_expand.weight\", \"_blocks.7._se_expand.bias\", \"_blocks.7._project_conv.weight\", \"_blocks.7._bn2.weight\", \"_blocks.7._bn2.bias\", \"_blocks.7._bn2.running_mean\", \"_blocks.7._bn2.running_var\", \"_blocks.8._expand_conv.weight\", \"_blocks.8._bn0.weight\", \"_blocks.8._bn0.bias\", \"_blocks.8._bn0.running_mean\", \"_blocks.8._bn0.running_var\", \"_blocks.8._depthwise_conv.weight\", \"_blocks.8._bn1.weight\", \"_blocks.8._bn1.bias\", \"_blocks.8._bn1.running_mean\", \"_blocks.8._bn1.running_var\", \"_blocks.8._se_reduce.weight\", \"_blocks.8._se_reduce.bias\", \"_blocks.8._se_expand.weight\", \"_blocks.8._se_expand.bias\", \"_blocks.8._project_conv.weight\", \"_blocks.8._bn2.weight\", \"_blocks.8._bn2.bias\", \"_blocks.8._bn2.running_mean\", \"_blocks.8._bn2.running_var\", \"_blocks.9._expand_conv.weight\", \"_blocks.9._bn0.weight\", \"_blocks.9._bn0.bias\", \"_blocks.9._bn0.running_mean\", \"_blocks.9._bn0.running_var\", \"_blocks.9._depthwise_conv.weight\", \"_blocks.9._bn1.weight\", \"_blocks.9._bn1.bias\", \"_blocks.9._bn1.running_mean\", \"_blocks.9._bn1.running_var\", \"_blocks.9._se_reduce.weight\", \"_blocks.9._se_reduce.bias\", \"_blocks.9._se_expand.weight\", \"_blocks.9._se_expand.bias\", \"_blocks.9._project_conv.weight\", \"_blocks.9._bn2.weight\", \"_blocks.9._bn2.bias\", \"_blocks.9._bn2.running_mean\", \"_blocks.9._bn2.running_var\", \"_blocks.10._expand_conv.weight\", \"_blocks.10._bn0.weight\", \"_blocks.10._bn0.bias\", \"_blocks.10._bn0.running_mean\", \"_blocks.10._bn0.running_var\", \"_blocks.10._depthwise_conv.weight\", \"_blocks.10._bn1.weight\", \"_blocks.10._bn1.bias\", \"_blocks.10._bn1.running_mean\", \"_blocks.10._bn1.running_var\", \"_blocks.10._se_reduce.weight\", \"_blocks.10._se_reduce.bias\", \"_blocks.10._se_expand.weight\", \"_blocks.10._se_expand.bias\", \"_blocks.10._project_conv.weight\", \"_blocks.10._bn2.weight\", \"_blocks.10._bn2.bias\", \"_blocks.10._bn2.running_mean\", \"_blocks.10._bn2.running_var\", \"_blocks.11._expand_conv.weight\", \"_blocks.11._bn0.weight\", \"_blocks.11._bn0.bias\", \"_blocks.11._bn0.running_mean\", \"_blocks.11._bn0.running_var\", \"_blocks.11._depthwise_conv.weight\", \"_blocks.11._bn1.weight\", \"_blocks.11._bn1.bias\", \"_blocks.11._bn1.running_mean\", \"_blocks.11._bn1.running_var\", \"_blocks.11._se_reduce.weight\", \"_blocks.11._se_reduce.bias\", \"_blocks.11._se_expand.weight\", \"_blocks.11._se_expand.bias\", \"_blocks.11._project_conv.weight\", \"_blocks.11._bn2.weight\", \"_blocks.11._bn2.bias\", \"_blocks.11._bn2.running_mean\", \"_blocks.11._bn2.running_var\", \"_blocks.12._expand_conv.weight\", \"_blocks.12._bn0.weight\", \"_blocks.12._bn0.bias\", \"_blocks.12._bn0.running_mean\", \"_blocks.12._bn0.running_var\", \"_blocks.12._depthwise_conv.weight\", \"_blocks.12._bn1.weight\", \"_blocks.12._bn1.bias\", \"_blocks.12._bn1.running_mean\", \"_blocks.12._bn1.running_var\", \"_blocks.12._se_reduce.weight\", \"_blocks.12._se_reduce.bias\", \"_blocks.12._se_expand.weight\", \"_blocks.12._se_expand.bias\", \"_blocks.12._project_conv.weight\", \"_blocks.12._bn2.weight\", \"_blocks.12._bn2.bias\", \"_blocks.12._bn2.running_mean\", \"_blocks.12._bn2.running_var\", \"_blocks.13._expand_conv.weight\", \"_blocks.13._bn0.weight\", \"_blocks.13._bn0.bias\", \"_blocks.13._bn0.running_mean\", \"_blocks.13._bn0.running_var\", \"_blocks.13._depthwise_conv.weight\", \"_blocks.13._bn1.weight\", \"_blocks.13._bn1.bias\", \"_blocks.13._bn1.running_mean\", \"_blocks.13._bn1.running_var\", \"_blocks.13._se_reduce.weight\", \"_blocks.13._se_reduce.bias\", \"_blocks.13._se_expand.weight\", \"_blocks.13._se_expand.bias\", \"_blocks.13._project_conv.weight\", \"_blocks.13._bn2.weight\", \"_blocks.13._bn2.bias\", \"_blocks.13._bn2.running_mean\", \"_blocks.13._bn2.running_var\", \"_blocks.14._expand_conv.weight\", \"_blocks.14._bn0.weight\", \"_blocks.14._bn0.bias\", \"_blocks.14._bn0.running_mean\", \"_blocks.14._bn0.running_var\", \"_blocks.14._depthwise_conv.weight\", \"_blocks.14._bn1.weight\", \"_blocks.14._bn1.bias\", \"_blocks.14._bn1.running_mean\", \"_blocks.14._bn1.running_var\", \"_blocks.14._se_reduce.weight\", \"_blocks.14._se_reduce.bias\", \"_blocks.14._se_expand.weight\", \"_blocks.14._se_expand.bias\", \"_blocks.14._project_conv.weight\", \"_blocks.14._bn2.weight\", \"_blocks.14._bn2.bias\", \"_blocks.14._bn2.running_mean\", \"_blocks.14._bn2.running_var\", \"_blocks.15._expand_conv.weight\", \"_blocks.15._bn0.weight\", \"_blocks.15._bn0.bias\", \"_blocks.15._bn0.running_mean\", \"_blocks.15._bn0.running_var\", \"_blocks.15._depthwise_conv.weight\", \"_blocks.15._bn1.weight\", \"_blocks.15._bn1.bias\", \"_blocks.15._bn1.running_mean\", \"_blocks.15._bn1.running_var\", \"_blocks.15._se_reduce.weight\", \"_blocks.15._se_reduce.bias\", \"_blocks.15._se_expand.weight\", \"_blocks.15._se_expand.bias\", \"_blocks.15._project_conv.weight\", \"_blocks.15._bn2.weight\", \"_blocks.15._bn2.bias\", \"_blocks.15._bn2.running_mean\", \"_blocks.15._bn2.running_var\", \"_conv_head.weight\", \"_bn1.weight\", \"_bn1.bias\", \"_bn1.running_mean\", \"_bn1.running_var\", \"_fc.weight\", \"_fc.bias\". \n\tUnexpected key(s) in state_dict: \"conv1.weight\", \"bn1.weight\", \"bn1.bias\", \"bn1.running_mean\", \"bn1.running_var\", \"bn1.num_batches_tracked\", \"layer1.0.conv1.weight\", \"layer1.0.bn1.weight\", \"layer1.0.bn1.bias\", \"layer1.0.bn1.running_mean\", \"layer1.0.bn1.running_var\", \"layer1.0.bn1.num_batches_tracked\", \"layer1.0.conv2.weight\", \"layer1.0.bn2.weight\", \"layer1.0.bn2.bias\", \"layer1.0.bn2.running_mean\", \"layer1.0.bn2.running_var\", \"layer1.0.bn2.num_batches_tracked\", \"layer1.1.conv1.weight\", \"layer1.1.bn1.weight\", \"layer1.1.bn1.bias\", \"layer1.1.bn1.running_mean\", \"layer1.1.bn1.running_var\", \"layer1.1.bn1.num_batches_tracked\", \"layer1.1.conv2.weight\", \"layer1.1.bn2.weight\", \"layer1.1.bn2.bias\", \"layer1.1.bn2.running_mean\", \"layer1.1.bn2.running_var\", \"layer1.1.bn2.num_batches_tracked\", \"layer1.2.conv1.weight\", \"layer1.2.bn1.weight\", \"layer1.2.bn1.bias\", \"layer1.2.bn1.running_mean\", \"layer1.2.bn1.running_var\", \"layer1.2.bn1.num_batches_tracked\", \"layer1.2.conv2.weight\", \"layer1.2.bn2.weight\", \"layer1.2.bn2.bias\", \"layer1.2.bn2.running_mean\", \"layer1.2.bn2.running_var\", \"layer1.2.bn2.num_batches_tracked\", \"layer2.0.conv1.weight\", \"layer2.0.bn1.weight\", \"layer2.0.bn1.bias\", \"layer2.0.bn1.running_mean\", \"layer2.0.bn1.running_var\", \"layer2.0.bn1.num_batches_tracked\", \"layer2.0.conv2.weight\", \"layer2.0.bn2.weight\", \"layer2.0.bn2.bias\", \"layer2.0.bn2.running_mean\", \"layer2.0.bn2.running_var\", \"layer2.0.bn2.num_batches_tracked\", \"layer2.0.downsample.0.weight\", \"layer2.0.downsample.1.weight\", \"layer2.0.downsample.1.bias\", \"layer2.0.downsample.1.running_mean\", \"layer2.0.downsample.1.running_var\", \"layer2.0.downsample.1.num_batches_tracked\", \"layer2.1.conv1.weight\", \"layer2.1.bn1.weight\", \"layer2.1.bn1.bias\", \"layer2.1.bn1.running_mean\", \"layer2.1.bn1.running_var\", \"layer2.1.bn1.num_batches_tracked\", \"layer2.1.conv2.weight\", \"layer2.1.bn2.weight\", \"layer2.1.bn2.bias\", \"layer2.1.bn2.running_mean\", \"layer2.1.bn2.running_var\", \"layer2.1.bn2.num_batches_tracked\", \"layer2.2.conv1.weight\", \"layer2.2.bn1.weight\", \"layer2.2.bn1.bias\", \"layer2.2.bn1.running_mean\", \"layer2.2.bn1.running_var\", \"layer2.2.bn1.num_batches_tracked\", \"layer2.2.conv2.weight\", \"layer2.2.bn2.weight\", \"layer2.2.bn2.bias\", \"layer2.2.bn2.running_mean\", \"layer2.2.bn2.running_var\", \"layer2.2.bn2.num_batches_tracked\", \"layer2.3.conv1.weight\", \"layer2.3.bn1.weight\", \"layer2.3.bn1.bias\", \"layer2.3.bn1.running_mean\", \"layer2.3.bn1.running_var\", \"layer2.3.bn1.num_batches_tracked\", \"layer2.3.conv2.weight\", \"layer2.3.bn2.weight\", \"layer2.3.bn2.bias\", \"layer2.3.bn2.running_mean\", \"layer2.3.bn2.running_var\", \"layer2.3.bn2.num_batches_tracked\", \"layer3.0.conv1.weight\", \"layer3.0.bn1.weight\", \"layer3.0.bn1.bias\", \"layer3.0.bn1.running_mean\", \"layer3.0.bn1.running_var\", \"layer3.0.bn1.num_batches_tracked\", \"layer3.0.conv2.weight\", \"layer3.0.bn2.weight\", \"layer3.0.bn2.bias\", \"layer3.0.bn2.running_mean\", \"layer3.0.bn2.running_var\", \"layer3.0.bn2.num_batches_tracked\", \"layer3.0.downsample.0.weight\", \"layer3.0.downsample.1.weight\", \"layer3.0.downsample.1.bias\", \"layer3.0.downsample.1.running_mean\", \"layer3.0.downsample.1.running_var\", \"layer3.0.downsample.1.num_batches_tracked\", \"layer3.1.conv1.weight\", \"layer3.1.bn1.weight\", \"layer3.1.bn1.bias\", \"layer3.1.bn1.running_mean\", \"layer3.1.bn1.running_var\", \"layer3.1.bn1.num_batches_tracked\", \"layer3.1.conv2.weight\", \"layer3.1.bn2.weight\", \"layer3.1.bn2.bias\", \"layer3.1.bn2.running_mean\", \"layer3.1.bn2.running_var\", \"layer3.1.bn2.num_batches_tracked\", \"layer3.2.conv1.weight\", \"layer3.2.bn1.weight\", \"layer3.2.bn1.bias\", \"layer3.2.bn1.running_mean\", \"layer3.2.bn1.running_var\", \"layer3.2.bn1.num_batches_tracked\", \"layer3.2.conv2.weight\", \"layer3.2.bn2.weight\", \"layer3.2.bn2.bias\", \"layer3.2.bn2.running_mean\", \"layer3.2.bn2.running_var\", \"layer3.2.bn2.num_batches_tracked\", \"layer3.3.conv1.weight\", \"layer3.3.bn1.weight\", \"layer3.3.bn1.bias\", \"layer3.3.bn1.running_mean\", \"layer3.3.bn1.running_var\", \"layer3.3.bn1.num_batches_tracked\", \"layer3.3.conv2.weight\", \"layer3.3.bn2.weight\", \"layer3.3.bn2.bias\", \"layer3.3.bn2.running_mean\", \"layer3.3.bn2.running_var\", \"layer3.3.bn2.num_batches_tracked\", \"layer3.4.conv1.weight\", \"layer3.4.bn1.weight\", \"layer3.4.bn1.bias\", \"layer3.4.bn1.running_mean\", \"layer3.4.bn1.running_var\", \"layer3.4.bn1.num_batches_tracked\", \"layer3.4.conv2.weight\", \"layer3.4.bn2.weight\", \"layer3.4.bn2.bias\", \"layer3.4.bn2.running_mean\", \"layer3.4.bn2.running_var\", \"layer3.4.bn2.num_batches_tracked\", \"layer3.5.conv1.weight\", \"layer3.5.bn1.weight\", \"layer3.5.bn1.bias\", \"layer3.5.bn1.running_mean\", \"layer3.5.bn1.running_var\", \"layer3.5.bn1.num_batches_tracked\", \"layer3.5.conv2.weight\", \"layer3.5.bn2.weight\", \"layer3.5.bn2.bias\", \"layer3.5.bn2.running_mean\", \"layer3.5.bn2.running_var\", \"layer3.5.bn2.num_batches_tracked\", \"layer4.0.conv1.weight\", \"layer4.0.bn1.weight\", \"layer4.0.bn1.bias\", \"layer4.0.bn1.running_mean\", \"layer4.0.bn1.running_var\", \"layer4.0.bn1.num_batches_tracked\", \"layer4.0.conv2.weight\", \"layer4.0.bn2.weight\", \"layer4.0.bn2.bias\", \"layer4.0.bn2.running_mean\", \"layer4.0.bn2.running_var\", \"layer4.0.bn2.num_batches_tracked\", \"layer4.0.downsample.0.weight\", \"layer4.0.downsample.1.weight\", \"layer4.0.downsample.1.bias\", \"layer4.0.downsample.1.running_mean\", \"layer4.0.downsample.1.running_var\", \"layer4.0.downsample.1.num_batches_tracked\", \"layer4.1.conv1.weight\", \"layer4.1.bn1.weight\", \"layer4.1.bn1.bias\", \"layer4.1.bn1.running_mean\", \"layer4.1.bn1.running_var\", \"layer4.1.bn1.num_batches_tracked\", \"layer4.1.conv2.weight\", \"layer4.1.bn2.weight\", \"layer4.1.bn2.bias\", \"layer4.1.bn2.running_mean\", \"layer4.1.bn2.running_var\", \"layer4.1.bn2.num_batches_tracked\", \"layer4.2.conv1.weight\", \"layer4.2.bn1.weight\", \"layer4.2.bn1.bias\", \"layer4.2.bn1.running_mean\", \"layer4.2.bn1.running_var\", \"layer4.2.bn1.num_batches_tracked\", \"layer4.2.conv2.weight\", \"layer4.2.bn2.weight\", \"layer4.2.bn2.bias\", \"layer4.2.bn2.running_mean\", \"layer4.2.bn2.running_var\", \"layer4.2.bn2.num_batches_tracked\", \"fc.weight\", \"fc.bias\". "
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('model_effi-b0_weights.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59268f15",
   "metadata": {},
   "source": [
    "### Check Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ea319e02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got9549/10197 with accuracy         93.64518976169461%\n",
      "[[ 510.    5.   83.]\n",
      " [  14. 9030.  155.]\n",
      " [   0.  391.    9.]]\n"
     ]
    }
   ],
   "source": [
    "# model.eval()\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def check_accuracy(loader, model):\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    \n",
    "    Conf_matrix = np.zeros((3, 3))\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images = images.to('cuda')\n",
    "            labels = labels.to('cuda')\n",
    "            results = model(images)\n",
    "            _, predictions = results.max(1)\n",
    "#             print(predictions)\n",
    "            if labels==0:\n",
    "                if predictions==labels:\n",
    "                    Conf_matrix[0][0] += 1\n",
    "                elif predictions==1:\n",
    "                    Conf_matrix[0][1] += 1\n",
    "                elif predictions==2:\n",
    "                    Conf_matrix[0][2] += 1\n",
    "            elif labels==1:\n",
    "                if predictions==labels:\n",
    "                    Conf_matrix[1][1] += 1\n",
    "                elif predictions==0:\n",
    "                    Conf_matrix[1][0] += 1\n",
    "                elif predictions==2:\n",
    "                    Conf_matrix[1][2] += 1\n",
    "            elif labels==2:\n",
    "                if predictions==labels:\n",
    "                    Conf_matrix[2][2] += 1\n",
    "                elif predictions==0:\n",
    "                    Conf_matrix[2][0] += 1\n",
    "                elif predictions==1:\n",
    "                    Conf_matrix[2][1] += 1\n",
    "                    \n",
    "            num_correct += (predictions==labels).sum()\n",
    "            num_samples += predictions.size(0)\n",
    "        \n",
    "        print(f'Got{num_correct}/{num_samples} with accuracy \\\n",
    "        {float(num_correct)/float(num_samples)*100}%')\n",
    "        np.set_printoptions(suppress=True)\n",
    "        print(Conf_matrix)\n",
    "        \n",
    "test_loader = DataLoader(dataset=test_set, batch_size=1, shuffle=True)        \n",
    "check_accuracy(test_loader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ef40c8f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "tesfsd =np.zeros((3,3))\n",
    "tesfsd.shape\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
