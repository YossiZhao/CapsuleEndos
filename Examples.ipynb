{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5db4d060",
   "metadata": {},
   "source": [
    "### Some functions you often use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf1990d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "#device\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print (device)\n",
    "\n",
    "# tensor\n",
    "X = torch.rand(1, 28, 28, device=device)\n",
    "print(X)\n",
    "print(X.shape)\n",
    "\n",
    "a.tolist()  # returns the tensor as a list\n",
    "a.item()   # Returns a value of this tensor as a standard Python number. Only works for tensor with one element.\n",
    "a.unsqueeze(1)  # If you need add a new dimension in tensor, you can use squeeze function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ccc49b",
   "metadata": {},
   "source": [
    "###  Load custome Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0b9481",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "\n",
    "class customDataset(Dataset):\n",
    "    def __init__(self, csv_file, data_dir, transform=None):\n",
    "        self.annotations = pd.read_csv(csv_file)\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        img_path = os.path.join(self.data_dir, self.annotations.iloc[index,1])\n",
    "        image = Image.open(img_path)\n",
    "        y_label = torch.tensor(int(self.annotations.iloc[index,2]))\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return (image, y_label)\n",
    "    \n",
    "\n",
    "transform = transforms.Compose([\n",
    "                                       transforms.Resize((224, 224)),\n",
    "                                       transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "train_set = customDataset(csv_file='./data/train_CapsuleEndos.csv', data_dir='./data/train_CapsuleEndos', \\\n",
    "                      transform=transform)   # 37191, 8 patients\n",
    "\n",
    "test_set = customDataset(csv_file='./data/test_CapsuleEndos.csv', data_dir='./data/test_CapsuleEndos', \\\n",
    "                      transform=transform)    # 10197, 2 patients\n",
    "\n",
    "# train_set, test_set = torch.utils.data.random_split(dataset, [40000, 7388])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5031378a",
   "metadata": {},
   "source": [
    "### Load ResNet34 from torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5cd5cf1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "model = resnet18()\n",
    "model.fc = nn.Linear(512, 3, bias=True)\n",
    "model.to('cuda')\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b682f94a",
   "metadata": {},
   "source": [
    "### Load ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6f2736",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torchvision.models import mobilenet_v3_small\n",
    "\n",
    "model = mobilenet_v3_small()\n",
    "model.classifier[3] = nn.Linear(1024, 3, bias=True)\n",
    "model.to('cuda')\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663d7968",
   "metadata": {},
   "source": [
    "### Load EfficientNet b0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26687c2c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from efficientnet_pytorch import EfficientNet\n",
    "\n",
    "model = EfficientNet.from_pretrained(\"efficientnet-b0\", num_classes=3).cuda()\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aaf0a4a",
   "metadata": {},
   "source": [
    "### Initialization: Dataset, Loss, Optimizer and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24990785",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# train_loader = DataLoader(dataset=train_set, batch_size=8, shuffle=True)\n",
    "init_lr = 0.1\n",
    "criterion = nn. CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=init_lr)\n",
    "# print(dir(optimizer))\n",
    "# Set lr_scheduler\n",
    "\n",
    "lambda1 = lambda epoch:  0.35 **epoch\n",
    "scheduler = optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda1)\n",
    "\n",
    "\n",
    "writer = SummaryWriter('runs/CapsuleEndos/tensorboard')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df2e6bf",
   "metadata": {},
   "source": [
    "### Check Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26cfc9ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model.eval()\n",
    "\n",
    "\n",
    "\n",
    "# def check_accuracy(loader, model):\n",
    "#     num_correct = 0\n",
    "#     num_samples = 0\n",
    "#     model.eval()\n",
    "    \n",
    "#     with torch.no_grad():\n",
    "#         for images, labels in loader:\n",
    "#             images = images.to('cuda')\n",
    "#             labels = labels.to('cuda')\n",
    "#             results = model(images)\n",
    "#             _, predictions = results.max(1)\n",
    "#             num_correct += (predictions==labels).sum()\n",
    "#             num_samples += predictions.size(0)\n",
    "        \n",
    "#         print(f'Got{num_correct}/{num_samples} with accuracy \\\n",
    "#         {float(num_correct)/float(num_samples)*100}%')\n",
    "        \n",
    "import numpy as np        \n",
    "        \n",
    "def check_accuracy(loader, model):\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    \n",
    "    Conf_matrix = np.zeros((3, 3))\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images = images.to('cuda')\n",
    "            labels = labels.to('cuda')\n",
    "            results = model(images)\n",
    "            _, predictions = results.max(1)\n",
    "#             print(predictions)\n",
    "            if labels==0:\n",
    "                if predictions==labels:\n",
    "                    Conf_matrix[0][0] += 1\n",
    "                elif predictions==1:\n",
    "                    Conf_matrix[0][1] += 1\n",
    "                elif predictions==2:\n",
    "                    Conf_matrix[0][2] += 1\n",
    "            elif labels==1:\n",
    "                if predictions==labels:\n",
    "                    Conf_matrix[1][1] += 1\n",
    "                elif predictions==0:\n",
    "                    Conf_matrix[1][0] += 1\n",
    "                elif predictions==2:\n",
    "                    Conf_matrix[1][2] += 1\n",
    "            elif labels==2:\n",
    "                if predictions==labels:\n",
    "                    Conf_matrix[2][2] += 1\n",
    "                elif predictions==0:\n",
    "                    Conf_matrix[2][0] += 1\n",
    "                elif predictions==1:\n",
    "                    Conf_matrix[2][1] += 1\n",
    "                    \n",
    "            num_correct += (predictions==labels).sum()\n",
    "            num_samples += predictions.size(0)\n",
    "        \n",
    "        print(f'Got{num_correct}/{num_samples} with accuracy \\\n",
    "        {float(num_correct)/float(num_samples)*100}%')\n",
    "        np.set_printoptions(suppress=True)\n",
    "        print(Conf_matrix)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50ec22a",
   "metadata": {},
   "source": [
    "###  Train, check, and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ab8275",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torchvision\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 128\n",
    "step = 0\n",
    "\n",
    "train_loader = DataLoader(dataset=train_set, batch_size=batch_size, \\\n",
    "                                  shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_set, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "        \n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    for batch_index, (data, targets) in enumerate(train_loader, 0):\n",
    "\n",
    "        # images, labels = dataiter.next()\n",
    "#         print('The shape of images is :', data.shape)\n",
    "        data = data.to('cuda')\n",
    "    \n",
    "        targets = targets.to('cuda')\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs, targets)\n",
    "#         losses.append(loss.item())\n",
    "#         print(loss)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        # calculate accuracy\n",
    "        _, predictions = outputs.max(1) \n",
    "        num_correct = (predictions==targets).sum()\n",
    "        training_acc = float(num_correct)/float(data.shape[0])\n",
    "#         accuracies.append(training_acc)\n",
    "\n",
    "        # plot things to tensorboard\n",
    "#                 image_grid = torchvision.utils.make_grid(data)\n",
    "#                 writer.add_image('Stomach_img', image_grid)\n",
    "#                 writer.add_histogram('fc', model.fc.weight)\n",
    "        writer.add_scalar('Training Loss', loss, global_step=step)\n",
    "        writer.add_scalar('Training Accuracy', training_acc, global_step=step)\n",
    "\n",
    "\n",
    "        step += 1\n",
    "        print(f'Step: {step}')\n",
    "        print('Training Accuracy', training_acc)\n",
    "    \n",
    "    scheduler.step()\n",
    "    check_accuracy(test_loader, model)\n",
    "    torch.save(model.state_dict(), 'model_effi-b0_weights.pth')\n",
    "    model.train()\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a27c620",
   "metadata": {},
   "source": [
    "###  Save and Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d94cc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving and Loading Model Weights\n",
    "model = models.vgg16(pretrained=True)\n",
    "torch.save(model.state_dict(), 'model_weights.pth')\n",
    "\n",
    "model = models.vgg16() \n",
    "model.load_state_dict(torch.load('model_weights.pth'))\n",
    "\n",
    "'''\n",
    "be sure to call model.eval() method before inferencing to set the \n",
    "dropout and batch normalization layers to evaluation mode. \n",
    "Failing to do this will yield inconsistent inference results.\n",
    "''' \n",
    "\n",
    "model.eval()\n",
    "\n",
    "\n",
    "# Saving and Loading Models with Shapes\n",
    "torch.save(model, 'model.pth')\n",
    "\n",
    "model = torch.load('model.pth')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
